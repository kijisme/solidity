{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smartbugs.json 143\n",
      "error.json 388\n",
      "clean.json 2354\n",
      "solidifi.json 350\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "root_json = '/workspaces/solidity/json'\n",
    "for json_file in os.listdir(root_json):\n",
    "    with open(os.path.join(root_json, json_file), 'r') as f:\n",
    "        items = json.load(f)\n",
    "    print(json_file, len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "dir = '/workspaces/solidity/integrate_dataset'\n",
    "for vuln in os.listdir(dir):\n",
    "    if vuln == 'clean':\n",
    "        continue\n",
    "    path = os.path.join(dir, vuln, 'integrate', 'vulnerabilities.json')\n",
    "    new_path = os.path.join(dir, vuln, 'integrate', 'vuln_vulnerabilities.json')\n",
    "    os.rename(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path_error = '/workspaces/solidity/error.json'\n",
    "path_clean = '/workspaces/solidity/integrate_dataset/clean/clean_vulnerabilities.json'\n",
    "\n",
    "with open(path_error, 'r') as f:\n",
    "    item_error = json.load(f)\n",
    "\n",
    "with open(path_clean, 'r') as f:\n",
    "    item_clean = json.load(f)\n",
    "\n",
    "for error in item_error:\n",
    "    for clean in item_clean:\n",
    "        if error['name'] == clean['name']:\n",
    "            clean['version'] = '0.5.0'\n",
    "\n",
    "with open(path_clean, 'w') as f:\n",
    "     json.dump(item_clean, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "cfg_path = '/workspaces/solidity/integrate_dataset/other/integrate/cfg.gpickle'\n",
    "cfg = nx.read_gpickle(cfg_path)\n",
    "\n",
    "all_function = {}\n",
    "for node, node_data in cfg.nodes(data=True):\n",
    "    if node_data['source_file'] not in all_function.keys():\n",
    "        all_function[node_data['source_file']] = []\n",
    "    if node_data['node_type'] == 'FUNCTION':\n",
    "        all_function[node_data['source_file']].append(node_data['node_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "cg_path = '/workspaces/solidity/integrate_dataset/other/integrate/cg.gpickle'\n",
    "cg = nx.read_gpickle(cg_path)\n",
    "\n",
    "all_function_cg = {}\n",
    "for node, node_data in cg.nodes(data=True):\n",
    "    # print(node_data['source_file'])\n",
    "    if node_data['source_file'] not in all_function_cg.keys():\n",
    "        all_function_cg[node_data['source_file']] = []\n",
    "    if node_data['node_type'].split('_')[-1] == 'function':\n",
    "        all_function_cg[node_data['source_file']].append(node_data['node_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2\n",
      "8\n",
      "38\n",
      "65\n",
      "22\n"
     ]
    }
   ],
   "source": [
    "for file in all_function:\n",
    "    print(len(all_function[file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1\n",
      "7\n",
      "21\n",
      "42\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for file in all_function_cg:\n",
    "    print(len(all_function_cg[file]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched global version to 0.4.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched global version to 0.4.16\n",
      "Switched global version to 0.4.21\n",
      "Switched global version to 0.4.0\n",
      "Switched global version to 0.4.0\n",
      "Switched global version to 0.4.24\n",
      "Switched global version to 0.4.25\n",
      "Switched global version to 0.4.13\n",
      "Switched global version to 0.4.24\n",
      "Switched global version to 0.4.22\n",
      "Switched global version to 0.4.18\n",
      "Switched global version to 0.4.24\n",
      "Switched global version to 0.4.24\n",
      "Switched global version to 0.4.23\n",
      "Switched global version to 0.4.19\n",
      "Switched global version to 0.4.18\n",
      "[531] [362]\n",
      "[531] [316]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "from slither.slither import Slither\n",
    "\n",
    "def get_path_and_version(error_dir):\n",
    "    path_version_dir = []\n",
    "    dataset_dir = '/workspaces/solidity/integrate_dataset'\n",
    "\n",
    "    for error_ in os.listdir(error_dir):\n",
    "        error_name = error_.split('_error.json')[0]\n",
    "        source_json_path = os.path.join(error_dir, error_)\n",
    "        target_json_path = os.path.join(dataset_dir, error_name, 'integrate', 'vulnerabilities.json')\n",
    "        with open(source_json_path, 'r') as f:\n",
    "            source = json.load(f)\n",
    "        with open(target_json_path, 'r') as f:\n",
    "            target = json.load(f)\n",
    "        for source_item in source['vuln']:\n",
    "            for target_item in target:\n",
    "                if source_item == target_item['name'].split('.sol')[0]:\n",
    "                    path_version_dir.append(target_item)\n",
    "    return path_version_dir\n",
    "\n",
    "def get_cfg_functions(slither, sol_file_name):\n",
    "    functions = set()\n",
    "    for contract in slither.contracts:\n",
    "        for function in contract.functions + contract.modifiers:\n",
    "            token = f'{sol_file_name}_{contract.name}_{function.full_name}'\n",
    "            # token = function.contract_declarer.name\n",
    "            functions.add(token) \n",
    "    return functions\n",
    "\n",
    "def get_cg_functions(slither, sol_file_name):\n",
    "    \n",
    "    all_functionss = [\n",
    "        compilation_unit.functions for compilation_unit in slither.compilation_units\n",
    "    ]\n",
    "    all_functions = [item for sublist in all_functionss for item in sublist]\n",
    "    # constract = set([function.contract_declarer.name for function in all_functions])\n",
    "    all_functions_as_dict = {\n",
    "            function.canonical_name: function for function in all_functions\n",
    "        }\n",
    "    functions = all_functions_as_dict.values()\n",
    "\n",
    "    functions = [f'{sol_file_name}_{function.contract_declarer.name}_{function.full_name}' for function in all_functions]\n",
    "    return functions\n",
    "\n",
    "def count_f_num(graph_dir, type):\n",
    "    count = 0\n",
    "    all_fun = []\n",
    "    graph = nx.read_gpickle(graph_dir)\n",
    "    for node, node_data in graph.nodes(data=True):\n",
    "        if type == 'cfg':\n",
    "            if node_data['node_type'] == 'FUNCTION':\n",
    "                count = count + 1\n",
    "                all_fun.append(node_data['node_token'])\n",
    "        elif type == 'cg':\n",
    "            if node_data['node_type'] == 'fallback_function' or node_data['node_type'] == 'contract_function':\n",
    "                count = count + 1\n",
    "                all_fun.append(node_data['node_token'])\n",
    "    return count, all_fun\n",
    "\n",
    "# error_dir = '/workspaces/solidity/error'\n",
    "# path_version_dir = get_path_and_version(error_dir)\n",
    "# print(len(path_version_dir))\n",
    "# vuln_type = [x for x in os.listdir('/workspaces/solidity/integrate_dataset') if x!='clean']\n",
    "vuln_type = ['bad_randomness']\n",
    "cfg_f_counts = []\n",
    "cg_f_counts = []\n",
    "\n",
    "cfg_counts = []\n",
    "cg_counts = []\n",
    "\n",
    "for vuln in vuln_type:\n",
    "    dir = f'/workspaces/solidity/integrate_dataset/{vuln}/integrate'\n",
    "    json_dir = os.path.join(dir, 'vulnerabilities.json')\n",
    "    cfg_dir = os.path.join(dir, 'cfg.gpickle')\n",
    "    cg_dir = os.path.join(dir, 'cg.gpickle')\n",
    "\n",
    "    with open(json_dir, 'r') as f:\n",
    "        path_version_dir =json.load(f)\n",
    "\n",
    "    cfg_f_count , all_cfg = count_f_num(cfg_dir, 'cfg')\n",
    "    cg_f_count , all_cg = count_f_num(cg_dir, 'cg')\n",
    "\n",
    "    cfg_functions = []\n",
    "    cg_functions = []\n",
    "\n",
    "    for file_item in path_version_dir:\n",
    "        version = file_item['version']\n",
    "        # 设置为当前版本\n",
    "        command = f\"solc-select use {version}\"\n",
    "        subprocess.run(command, shell=True)\n",
    "        # 获取文件路径\n",
    "        sol_file_path = file_item['path']\n",
    "        # 获取文件名称\n",
    "        sol_file_name = file_item['name']\n",
    "        # 使用slither解析\n",
    "        slither = Slither(sol_file_path)\n",
    "\n",
    "        cfg_function = get_cfg_functions(slither, sol_file_name)\n",
    "        cg_function = get_cg_functions(slither, sol_file_name)\n",
    "\n",
    "        cfg_functions.extend(list(cfg_function))\n",
    "        cg_functions.extend(list(cg_function))\n",
    "\n",
    "    cfg_f_counts.append(cfg_f_count)\n",
    "    cg_f_counts.append(cg_f_count)\n",
    "\n",
    "    cfg_counts.append(len(cfg_functions))\n",
    "    cg_counts.append(len(set(cg_functions)))\n",
    "\n",
    "    print(cfg_f_counts, cg_f_counts)\n",
    "    print(cfg_counts, cg_counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531] [362]\n",
      "[531] [316]\n",
      "True\n",
      "True\n",
      "46\n",
      "{'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_StandardToken_whenNotPaused()', 'clean_0x9e86da479dfdbc618d0a46759555154bdb06d06d.sol_CliftonSavingsBankInternationalUnionCoins_safeAdd(uint256,uint256)', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_Ownable_onlyOwner()', 'clean_0x4983f767b1bc44328e434729ddabea0a064ca1ac.sol_Constant__mint(address,uint256)', 'clean_0x4983f767b1bc44328e434729ddabea0a064ca1ac.sol_Constant__burn(address,uint256)', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_Ownable_onlyOwner()', 'clean_0x8fbcb3f7a4c48dd9500ba20b5254c08d75403ba1.sol_MobilinkToken_beforeStageOneClosed()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_ERC223Token_whenNotPaused()', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_MintableToken_canMint()', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_JLCToken_balanceOf(address)', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_DipToken_shouldNotBeLockedIn(address)', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_NAi_onlyOwner()', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_Pausable_onlyOwner()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_TokenRepository_onlyOwner()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_Ownable_onlyOwner()', 'clean_0x8fbcb3f7a4c48dd9500ba20b5254c08d75403ba1.sol_MobilinkToken_onlyOwner()', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_MintableToken_onlyOwner()', 'clean_0x9e86da479dfdbc618d0a46759555154bdb06d06d.sol_Ownable_onlyOwner()', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_JLCToken_transfer(address,uint256)', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_PausableToken_whenNotPaused()', 'smartbugs_bad_randomness_smart_billions.sol_BasicToken_commitDividend(address)', 'smartbugs_bad_randomness_smart_billions.sol_StandardToken_commitDividend(address)', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_Pausable_whenPaused()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_Pausable_onlyOwner()', 'smartbugs_bad_randomness_lucky_doubler.sol_LuckyDoubler_onlyowner()', 'clean_0xd138be69f9b7c0028a89a43c6597d900932438a1.sol_DealsRootStorage_onlyOwner()', 'clean_0xd138be69f9b7c0028a89a43c6597d900932438a1.sol_Ownable_onlyOwner()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_TokenRepository_transferOwnership(address)', 'clean_0x8fbcb3f7a4c48dd9500ba20b5254c08d75403ba1.sol_MobilinkToken_afterStageOneClosed()', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_Pausable_whenNotPaused()', 'smartbugs_bad_randomness_smart_billions.sol_BasicToken_onlyPayloadSize(uint256)', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_Pausable_onlyOwner()', 'smartbugs_bad_randomness_smart_billions.sol_SmartBillions_onlyOwner()', 'smartbugs_bad_randomness_smart_billions.sol_SmartBillions_onlyAnimator()', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_JLCToken_onlyOwner()', 'clean_0x9e86da479dfdbc618d0a46759555154bdb06d06d.sol_CliftonSavingsBankInternationalUnionCoins_safeSub(uint256,uint256)', 'clean_0x4983f767b1bc44328e434729ddabea0a064ca1ac.sol_Constant__transfer(address,address,uint256)', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_Pausable_whenPaused()', 'clean_0x4983f767b1bc44328e434729ddabea0a064ca1ac.sol_Constant_onlyAdmin()', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_DipToken_onlyOwner()', 'clean_0xa07519032c24799354b6efedd38c3b704226b2f2.sol_Pausable_whenNotPaused()', 'smartbugs_bad_randomness_blackjack.sol_BlackJack_gameIsGoingOn()', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_Pausable_whenPaused()', 'clean_0x26fe2d1d3d288f2f2fe5bfff40be832e814137b6.sol_StandardToken_onlyOwner()', 'smartbugs_bad_randomness_smart_billions.sol_StandardToken_onlyPayloadSize(uint256)', 'clean_0xc719d010b63e5bbf2c0551872cd5316ed26acd83.sol_Pausable_whenNotPaused()'}\n"
     ]
    }
   ],
   "source": [
    "print(cfg_f_counts, cg_f_counts)\n",
    "print(cfg_counts, cg_counts)\n",
    "\n",
    "print(set(all_cfg) >= set(all_cg))\n",
    "print(set(all_cg) >= set(cg_functions))\n",
    "# print(set(cg_functions) <= set(cfg_functions))\n",
    "# print(set(cfg_functions) <= set(all_cfg))\n",
    "print(len(set(all_cg) - set(cg_functions)))\n",
    "print(set(all_cg) - set(cg_functions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import networkx as nx\n",
    "\n",
    "def count_f_num(graph_dir, type):\n",
    "    count = 0\n",
    "    all_fun = []\n",
    "    graph = nx.read_gpickle(graph_dir)\n",
    "    for node, node_data in graph.nodes(data=True):\n",
    "        if type == 'cfg':\n",
    "            if node_data['node_type'] == 'FUNCTION':\n",
    "                count = count + 1\n",
    "                all_fun.append(node_data['node_token'])\n",
    "        elif type == 'cg':\n",
    "            if node_data['node_type'] == 'fallback_function' or node_data['node_type'] == 'contract_function':\n",
    "                count = count + 1\n",
    "                all_fun.append(node_data['node_token'])\n",
    "    return all_fun\n",
    "\n",
    "# [x for x in os.listdir('/workspaces/solidity/integrate_dataset') if x != 'clean']\n",
    "for vuln in ['bad_randomness']:\n",
    "    path_cg = f'/workspaces/solidity/integrate_dataset/{vuln}/integrate/cg.gpickle'\n",
    "    path_cfg = f'/workspaces/solidity/integrate_dataset/{vuln}/integrate/cfg.gpickle'\n",
    "\n",
    "\n",
    "    graph_cg = count_f_num(path_cg, 'cg')\n",
    "    graph_cfg = count_f_num(path_cg, 'cg')\n",
    "\n",
    "    tokens = set(graph_cg) - set(graph_cfg)\n",
    "    graph = nx.read_gpickle(path_cg)\n",
    "    for node, node_data in graph.nodes(data=True):\n",
    "        for token in tokens:\n",
    "            if node_data['node_token'] == token:\n",
    "                for source, target, edge_data in graph.edges(data=True):\n",
    "                    if node == source or node == target:\n",
    "                        # if edge_data['edge_type'] != 'external_call':\n",
    "                        print(edge_data['edge_type'], node_data['node_token'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched global version to 0.5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructor()\n",
      "owner()\n",
      "isOwner()\n",
      "renounceOwnership()\n",
      "transferOwnership(address)\n",
      "_transferOwnership(address)\n",
      "onlyOwner()\n"
     ]
    }
   ],
   "source": [
    "# 对于继承的变量的解析\n",
    "import subprocess\n",
    "import networkx as nx\n",
    "from slither.slither import Slither\n",
    "from slither.core.cfg.node import NodeType\n",
    "\n",
    "version = '0.5.0'\n",
    "# 设置为当前版本\n",
    "command = f\"solc-select use {version}\"\n",
    "subprocess.run(command, shell=True)\n",
    "# 获取文件路径\n",
    "sol_file_path = '/workspaces/solidity/clean_0x20b1bc618f79d9977b7cce3f0523128178ea6a7b.sol'\n",
    "# 使用slither解析\n",
    "slither = Slither(sol_file_path)\n",
    "\n",
    "for contract in slither.contracts:\n",
    "    # print('name:', contract.name)\n",
    "    # print([x.name for x in contract.state_variables])\n",
    "    if contract.name == 'Ownable':\n",
    "        # print([x.name for x in contract.state_variables])\n",
    "        for function in contract.functions + contract.modifiers:\n",
    "            if function.contract_declarer.name != contract.name:\n",
    "                    # 继承的私有函数不属于当前合约\n",
    "                    if function.visibility == 'private' or function.visibility == 'external':\n",
    "                        continue\n",
    "            print(function.full_name)\n",
    "        #     print('----', function.contract.name, function.name, function.visibility, [(x.full_name, x.contract.name, x.visibility) for x in function.state_variables_read + function.state_variables_written])\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arithmetic\n",
      "130 130\n",
      "65 65\n",
      "short_addresses\n",
      "2 2\n",
      "1 1\n",
      "other\n",
      "6 6\n",
      "3 3\n",
      "bad_randomness\n",
      "16 16\n",
      "8 8\n",
      "access_control\n",
      "136 136\n",
      "68 68\n",
      "front_running\n",
      "108 108\n",
      "54 54\n",
      "unchecked_low_level_calls\n",
      "204 204\n",
      "102 102\n",
      "reentrancy\n",
      "162 162\n",
      "81 81\n",
      "denial_of_service\n",
      "112 112\n",
      "56 56\n",
      "time_manipulation\n",
      "110 110\n",
      "55 55\n"
     ]
    }
   ],
   "source": [
    "# 检测json文件是否出现重复\n",
    "import json\n",
    "import os\n",
    "\n",
    "def check_diff(json_path):\n",
    "    all_index = {}\n",
    "    with open(json_path) as f:\n",
    "        items = json.load(f)\n",
    "    for item in items:\n",
    "        if item['name'] not in all_index.keys():\n",
    "            all_index[item['name']] = 1\n",
    "        else:\n",
    "            all_index[item['name']] += 1\n",
    "    \n",
    "    for index in all_index:\n",
    "        if all_index[index] > 1:\n",
    "            print(index, all_index[index])\n",
    "\n",
    "def check_num(json_path_1, json_path_2):\n",
    "    with open(json_path_1) as f:\n",
    "        len_1 = len(json.load(f))\n",
    "    with open(json_path_2) as f:\n",
    "        len_2 = len(json.load(f))\n",
    "    print(len_1,len_2)\n",
    "\n",
    "def get_json_pair(dataset_root):\n",
    "    all_vuln = [x for x in os.listdir(dataset_root) if x != 'clean']\n",
    "    for vuln in all_vuln:\n",
    "        path_1 = os.path.join(dataset_root, vuln, 'integrate', 'vulnerabilities.json')\n",
    "        path_2 = os.path.join(dataset_root, vuln, 'integrate', 'graph_label.json')\n",
    "        path_3 = os.path.join(dataset_root, vuln, 'integrate', 'clean_vulnerabilities.json')\n",
    "        path_4 = os.path.join(dataset_root, vuln, 'integrate', 'vuln_vulnerabilities.json')\n",
    "        print(vuln)\n",
    "        check_num(path_1, path_2)\n",
    "        check_num(path_3, path_4)\n",
    "        check_diff(path_3)\n",
    "\n",
    "dataset_root = '/workspaces/solidity/integrate_dataset'\n",
    "get_json_pair(dataset_root)\n",
    "json_path = '/workspaces/solidity/integrate_dataset/clean/clean_vulnerabilities.json'\n",
    "# check_diff(json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [90, 240, 985, 1241, 1753, 70, 1736, 1943, 1077, 922, 406, 1846, 834, 1564, 2223, 1079, 1281, 598, 1608, 1464, 1438, 180, 1871, 1184, 1624, 1483, 1696, 726, 632, 1120, 1642, 1003, 1878, 2135, 752, 1629, 1033, 1772, 418, 156, 63, 2151, 632, 231, 1870, 633, 404, 626, 459, 872, 1717, 1868, 1202, 174, 225, 677, 688, 1067, 708, 1540, 1292, 2114, 355, 1891, 308]\n",
    "b = set(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1000\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.choice(a=np.arange(5), size=5, replace=False, p=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
